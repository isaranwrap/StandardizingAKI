{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime, random\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in file; managing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Read in dataframe - uncomment which data frame according to which you are working on\n",
    "\n",
    "#df = pd.read_csv('~/Desktop/patr/StandardizingAKI/inpatient 2014-2018 creatinine.csv') #1441707, 4\n",
    "#df = pd.read_csv(r'H:\\Data\\Standardized AKI definition\\dataset\\inpatient 2014-2018 creatinine.csv')\n",
    "df = pd.read_csv('/Users/saranmedical-smile/csv_files/inpatient 2014-2018 creatinine.csv')\n",
    "#df = pd.read_csv('/Users/saranmedical-smile/csv_files/covid creatinines.csv')\n",
    "\n",
    "df.pat_mrn_id = df.pat_mrn_id.str.strip('MR').astype('int') #Index with integers --> it's much quicker\n",
    "df.time = pd.to_datetime(df.time) # Convert to pandas datetime format\n",
    "print(df.dtypes) # Confirm all the column types are as we want it\n",
    "\n",
    "df.columns = ['mrn', #Renaming columns for ease\n",
    "              'enc',\n",
    "              'time',\n",
    "              'creat'] \n",
    "df.set_index(['time'], inplace=True)\n",
    "#df.set_index(['mrn', 'enc'], inplace=True) #Turn the index into a hierarchical tuple (mrn, enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions: add_rows(df),  add_delta_cols(df), returnAKIpatients(df), parallelizeAnalysis(df, num_cores)\n",
    "\n",
    "### add_rows()\n",
    "\n",
    "    Input: Pandas data frame \n",
    "\n",
    "    Output: Pandas data frame (w/ extra dummy rows containing back-calculated values)\n",
    "\n",
    "This function is the bulk of the computation - it adds dummy rows with the appropriate back-calculated values at the first encounter row. If one is only interested in those patients which have AKI according to the Rolling Window definition, the code should run in less than a minute and *add_rows()* isn't necessary. If you are interested in back-calculated AKI cases, then the analysis takes a bit longer (although still under an hour) and that's where *add_rows()* comes in. It simply finds the first encounter recorded for a patient, looks back between 7 and 365 days in the past and sees whether or not there are measured creatinine values. If there are, the mean of those values are put into the dummy row. Otherwise, a value calculated based on the estimated glomerular filtration rate (eGFR) equation from A New Equation to Estimate Glomerular Filtration Rate (Levey et. Al, 2009, https://pubmed.ncbi.nlm.nih.gov/19414839/) is used instead in the dummy row.  \n",
    "\n",
    "### parallelizeAnalysis()\n",
    "\n",
    "Parallelizes the analysis.\n",
    "\n",
    "### returnAKIpatients()\n",
    "\n",
    "Finds the patients with AKI according to the Rolling Window and/or the back-calculated definitions... runtime significantly depends on which definition you care for.\n",
    "\n",
    "### addDeltaCols()\n",
    "\n",
    "The way in which AKI is measured is based on the change in creatinine over a given period of time. As a proxy, $\\Delta creat$ and $\\Delta time$ columns are created to measure the change from one time point to another. This function calculates those values via the Split-Apply-Combine methodology on the original data frame: splitting by encounter, transforming via a backward shift, then taking the difference of values, then a forward shift, and then recombining the dataframe object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     20,
     56,
     91
    ]
   },
   "outputs": [],
   "source": [
    "def returnAKIpatients(df, aki_calc_type = 'rolling_window'):\n",
    "    \n",
    "    x = df.groupby('enc', sort=False)['creat'].rolling(pd.Timedelta('52hours'), min_periods=1).min()#.reset_index('enc').creat\n",
    "    y = df.groupby('enc', sort=False)['creat'].rolling(pd.Timedelta('172hours'), min_periods=1).min()#.reset_index('enc').creat\n",
    "\n",
    "    df = df.reset_index().set_index(['enc', 'time'])\n",
    "    \n",
    "    df['running_min_48hrs'] = x\n",
    "    df['running_min_7days'] = y\n",
    "    \n",
    "    df['running_delta_48hrs'] = np.round(df['creat'] - df['running_min_48hrs'], decimals = 3)\n",
    "    df['running_delta_7days'] = np.round(df['creat'] - df['running_min_7days'], decimals = 3)\n",
    "    \n",
    "    condition1 = df['running_delta_48hrs'] >= 0.3\n",
    "    condition2 = df['running_delta_7days'] >= 0.5*df['running_min_7days']\n",
    "    \n",
    "    df['aki'] = condition1 | condition2\n",
    "    \n",
    "    return df\n",
    "\n",
    "def OLD_returnAKIpatients(df, aki_calc_type = 'both', keep_extra_cols = True, num_cores=4):\n",
    "    \n",
    "    if aki_calc_type == 'rolling_window':\n",
    "        #Add the delta columns as described above\n",
    "        d = add_delta_cols(df)\n",
    "        \n",
    "        #Two conditions for rolling-window definition\n",
    "        condition1 = np.logical_and(d.delta_creat >= 0.3, d.delta_time <= datetime.timedelta(hours=48))\n",
    "        condition2 = np.logical_and(d.delta_creat >= d.creat.shift(1)*0.5, d.delta_time <= datetime.timedelta(days=7))    \n",
    "    \n",
    "        d['aki'] = condition1 | condition2\n",
    "        \n",
    "    elif aki_calc_type == 'back_calc':\n",
    "        #Now, we gotta go through the process of creating the dummy rows\n",
    "        split_dfs = np.array_split(df, num_cores)\n",
    "        with Pool(num_cores) as p:\n",
    "            result = p.map(add_rows, split_dfs)\n",
    "            d_ = pd.concat(result)\n",
    "        d = add_delta_cols(d_)\n",
    "        condition2 = np.logical_and(d.delta_creat >= d.creat.shift(1)*0.5, d.delta_time < datetime.timedelta(days=7))    \n",
    "        d['aki'] = condition2 & (d.delta_time == datetime.timedelta(0)) #Remember, back-calc doesn't include the 0.3 increase criterion... has to be a 50% increase\n",
    "        \n",
    "    elif aki_calc_type == 'both':\n",
    "        split_dfs = np.array_split(df, num_cores)\n",
    "        with Pool(num_cores) as p:\n",
    "            result = p.map(add_rows, split_dfs)\n",
    "            d_ = pd.concat(result)\n",
    "        d = add_delta_cols(d_)\n",
    "        \n",
    "        condition1 = np.logical_and(d.delta_creat >= 0.3, d.delta_time < datetime.timedelta(hours=48))\n",
    "        condition2 = np.logical_and(d.delta_creat >= d.creat.shift(1)*0.5, d.delta_time < datetime.timedelta(days=7))    \n",
    "        \n",
    "        d['aki'] = condition1 | condition2\n",
    "    \n",
    "    return d\n",
    "\n",
    "def add_rows(df):\n",
    "    '''\n",
    "    Input: Pandas data frame\n",
    "    Output: Pandas data frame\n",
    "    \n",
    "    This function is the bulk of the computation - it adds dummy rows with the appropriate back-calculated values\n",
    "    at the first encounter row. If one is only interested in those patients which have AKI according to the \n",
    "    Rolling Window definition, the code should run in less than a minute and *add_rows()* isn't necessary. \n",
    "    If you are interested in back-calculated AKI cases, then the analysis takes a bit longer \n",
    "    (although still under an hour) and that's where *add_rows()* comes in. It simply finds the first encounter \n",
    "    recorded for a patient, looks back between 7 and 365 days in the past and sees whether or not there are measured\n",
    "    creatinine values. If there are, the mean of those values are put into the dummy row. Otherwise, a value \n",
    "    calculated based on the estimated glomerular filtration rate (eGFR) equation from A New Equation to Estimate \n",
    "    Glomerular Filtration Rate (Levey et. Al, 2009, https://pubmed.ncbi.nlm.nih.gov/19414839/) is used instead \n",
    "    in the dummy row.  \n",
    "    '''\n",
    "    patient_dfs = df.groupby(['mrn'], sort=False) \n",
    "    patients = dict()\n",
    "    \n",
    "    for mrn, pat_df in patient_dfs:\n",
    "        patients[mrn] = pat_df\n",
    "        backcalc_rows = np.array(pat_df.reset_index().drop_duplicates(['mrn', 'enc']).index)\n",
    "        times_to_consider = [pat_df.iloc[indx].time for indx in backcalc_rows]\n",
    "\n",
    "        new_rows = pat_df.iloc[backcalc_rows].copy()\n",
    "        for i in range(1,len(times_to_consider)):\n",
    "            new_rows.iloc[i, new_rows.columns.get_loc('creat')] = pat_df.loc[np.logical_and(times_to_consider[i] - pat_df.time < datetime.timedelta(days=365),times_to_consider[i] - pat_df.time > datetime.timedelta(days=7)), 'creat'].mean()\n",
    "\n",
    "        mini_dfs = np.split(pat_df, backcalc_rows[1:])\n",
    "        mini_dfs = [pd.concat([new_rows.iloc[[indx]], dataframe]) for indx, dataframe in enumerate(mini_dfs)]\n",
    "        pat_df = pd.concat(mini_dfs)\n",
    "        patients[mrn] = pat_df\n",
    "        \n",
    "    return pd.concat(list(patients.values()))\n",
    "\n",
    "def add_delta_cols(df):\n",
    "    delta_df = df.groupby(['mrn', 'enc']).shift(-1) - df\n",
    "    df['delta_creat'] = np.round(delta_df['creat'].shift(1), decimals = 2)\n",
    "    df['delta_time'] = delta_df['time'].shift(1)\n",
    "    firstencs = df.reset_index().drop_duplicates('mrn') #Similarly, df.groupby(['mrn']).head(1)\n",
    "    df['first_enc'] = [i in firstencs.index for i in range(df.shape[0])]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returnAKIpatients(df)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x = df.groupby('mrn', sort=False)['creat'].rolling(pd.Timedelta('2days'), min_periods=1).min()#.reset_index('enc').creat\n",
    "y = df.groupby('mrn', sort=False)['creat'].rolling(pd.Timedelta('7days'), min_periods=1).min()#.reset_index('enc').creat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().set_index(['enc', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['running_min_48hrs'] = x\n",
    "df['running_min_7days'] = y\n",
    "\n",
    "df['running_delta_48hrs'] = np.round(df['creat'] - df['running_min_48hrs'], decimals = 3)\n",
    "df['running_delta_7days'] = np.round(df['creat'] - df['running_min_7days'], decimals = 3)    \n",
    "\n",
    "condition1 = df['running_delta_48hrs'] >= 0.3\n",
    "condition2 = df['running_delta_7days'] >= 0.5*df['running_min_7days']\n",
    "\n",
    "df['aki'] = condition1 | condition2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the rolling-window code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['running_min_48hrs'] = df.groupby('enc', sort=False)['creat'].rolling(pd.Timedelta('2days'), min_periods=1).min().values#reset_index('enc').creat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['running_min_7days'] = df.groupby('enc', sort=False)['creat'].rolling(pd.Timedelta('7days'), min_periods=1).min().values#reset_index('enc').creat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['running_delta_48hrs'] = np.round(df['creat'] - df['running_min_48hrs'], decimals = 3)\n",
    "df['running_delta_7days'] = np.round(df['creat'] - df['running_min_7days'], decimals = 3)\n",
    "\n",
    "condition1 = df['running_delta_48hrs'] >= 0.3\n",
    "condition2 = df['running_delta_7days'] >= 0.5*df['running_min_7days']\n",
    "\n",
    "df['aki'] = condition1 | condition2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking against Yu's flagger values\n",
    "\n",
    "Hey Yu, I'm looking at patient mrn 'MR1019104' in H:\\Data\\Standardized AKI definition\\dataset\\aki flagger inpatient 2014-2018.csv, we don't match on 2015-06-20 01:27:00 ... you flagged I wasn't sure if I missed something. Would you mind taking a look when you have a moment (no rush)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_yu = pd.read_csv(r'/Users/saranmedical-smile/csv_files/aki flagger inpatient 2014-2018.csv')\n",
    "df_yu['aki'] = df_yu['aki'].astype('bool')\n",
    "df_yu['time'] = pd.to_datetime(df_yu['time'])\n",
    "#df_yu = df_yu[:10000]\n",
    "df_yu.set_index(['pat_enc_csn_id', 'time'], inplace=True)\n",
    "print(df_yu.shape, df.shape)\n",
    "print(np.all(df.index == df_yu.index)) #Check whether the encounters are the same at least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycount = df.aki.sum()\n",
    "yucount = df_yu.aki.sum()\n",
    "print('My AKI count:', mycount, '| Yu AKI count:', yucount, '| Discrepancy: ', np.abs(yucount-mycount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Example case: we disagree on 1019104\n",
    "#df_yu[df_yu.pat_mrn_id == 'MR1019104']#.aki == df[df.mrn == 1019104].aki\n",
    "#df[df.mrn == 1019104]\n",
    "\n",
    "\n",
    "#These are the patients which we disagree on\n",
    "df.iloc[np.where(df.aki != df_yu.aki)[0]].mrn.unique()\n",
    "\n",
    "#The first one - 1002080 - accounts for 9 of our discrepancies. I am doing it by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We agree if I group at the level of patient instead of encounter ... cool :)\n",
    "tmp_df = df.loc[df.mrn == 1002080]\n",
    "tmp_df = tmp_df.reset_index('enc')\n",
    "tmp_df['running_min_48hrs'] = tmp_df.groupby('mrn', sort=False)['creat'].rolling(pd.Timedelta('2days'), min_periods=1).min().reset_index('mrn').creat\n",
    "tmp_df['running_min_7days'] = tmp_df.groupby('mrn', sort=False)['creat'].rolling(pd.Timedelta('7days'), min_periods=1).min().reset_index('mrn').creat\n",
    "\n",
    "tmp_df['running_delta_48hrs'] = np.round(tmp_df['creat'] - tmp_df['running_min_48hrs'], decimals = 3)\n",
    "tmp_df['running_delta_7days'] = np.round(tmp_df['creat'] - tmp_df['running_min_7days'], decimals = 3)\n",
    "\n",
    "condition1 = tmp_df['running_delta_48hrs'] >= 0.3\n",
    "condition2 = tmp_df['running_delta_7days'] >= 0.5*tmp_df['running_min_7days']\n",
    "\n",
    "tmp_df['aki'] = condition1 | condition2\n",
    "#tmp_df#.aki == df_yu.loc[df_yu.pat_mrn_id == 'MR1002080'].aki\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in COVID-19 cases, same analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cdf = pd.read_csv('/Users/saranmedical-smile/csv_files/covid creatinines.csv')\n",
    "cdf.pat_mrn_id = cdf.pat_mrn_id.str.strip('MR').astype('int') #Index with integers --> it's much quicker\n",
    "cdf.time = pd.to_datetime(cdf.time) # Convert to pandas datetime format\n",
    "cdf.admission = pd.to_datetime(cdf.admission)\n",
    "cdf.discharge = pd.to_datetime(cdf.discharge)\n",
    "cdf.drop(['enc_id',\n",
    "         'age',\n",
    "         'sex',\n",
    "         'inpatient',\n",
    "         'race',\n",
    "         'admission',\n",
    "         'discharge'], axis=1, inplace=True)\n",
    "print(cdf.dtypes) # Confirm all the column types are as we want it\n",
    "cdf.columns = ['mrn', #Renaming columns for ease\n",
    "              'enc',\n",
    "              'time',\n",
    "              'creat'] \n",
    "cdf.set_index(['time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#returnAKIpatients(cdf)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x = cdf.groupby('mrn', sort=False)['creat'].rolling(pd.Timedelta('52hours'), min_periods=1).min()#.reset_index('enc').creat\n",
    "y = cdf.groupby('mrn', sort=False)['creat'].rolling(pd.Timedelta('172hours'), min_periods=1).min()#.reset_index('enc').creat    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = cdf.reset_index().set_index(['enc', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf['running_min_48hrs'] = x.values\n",
    "cdf['running_min_7days'] = y.values\n",
    "\n",
    "cdf['running_delta_48hrs'] = np.round(cdf['creat'] - cdf['running_min_48hrs'], decimals = 3)\n",
    "cdf['running_delta_7days'] = np.round(cdf['creat'] - cdf['running_min_7days'], decimals = 3)    \n",
    "\n",
    "condition1 = cdf['running_delta_48hrs'] >= 0.3\n",
    "condition2 = cdf['running_delta_7days'] >= 0.5*cdf['running_min_7days']\n",
    "\n",
    "cdf['aki'] = condition1 | condition2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf.reset_index('enc', inplace=True)\n",
    "cdf.sort_index(inplace=True)\n",
    "cdf['aki_cumsum'] = cdf.aki.cumsum()\n",
    "#cdf['aki_cumsum_7d'] = cdf.reset_index('enc').aki.rolling(pd.Timedelta('7days')).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cdf.to_csv('/Users/saranmedical-smile/csv_files/covid19aki.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yu[df_yu.pat_mrn_id == 'MR1019104']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
