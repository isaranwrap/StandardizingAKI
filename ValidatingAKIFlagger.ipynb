{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime, random\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in file; managing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pat_mrn_id                 int32\n",
      "pat_enc_csn_id             int64\n",
      "time              datetime64[ns]\n",
      "creatinine               float64\n",
      "dtype: object\n",
      "Wall time: 3.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Read in dataframe\n",
    "\n",
    "#df = pd.read_csv('~/Desktop/patr/StandardizingAKI/inpatient 2014-2018 creatinine.csv') #1441707, 4\n",
    "df = pd.read_csv(r'H:\\Data\\Standardized AKI definition\\dataset\\inpatient 2014-2018 creatinine.csv')\n",
    "df.pat_mrn_id = df.pat_mrn_id.str.strip('MR').astype('int') #Index with integers --> it's much quicker\n",
    "df.time = pd.to_datetime(df.time) # Convert to pandas datetime format\n",
    "print(df.dtypes) # Confirm all the column types are as we want it\n",
    "\n",
    "df.columns = ['mrn', #Renaming columns for ease\n",
    "              'enc',\n",
    "              'time',\n",
    "              'creat'] \n",
    "df.set_index(['mrn', 'enc'], inplace=True) #Turn the index into a hierarchical tuple (mrn, enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions: add_rows(df),  add_delta_cols(df), returnAKIpatients(df), parallelizeAnalysis(df, num_cores)\n",
    "\n",
    "### add_rows()\n",
    "\n",
    "    Input: Pandas data frame \n",
    "\n",
    "    Output: Pandas data frame (w/ extra dummy rows containing back-calculated values)\n",
    "\n",
    "This function is the bulk of the computation - it adds dummy rows with the appropriate back-calculated values at the first encounter row. If one is only interested in those patients which have AKI according to the Rolling Window definition, the code should run in less than a minute and *add_rows()* isn't necessary. If you are interested in back-calculated AKI cases, then the analysis takes a bit longer (although still under an hour) and that's where *add_rows()* comes in. It simply finds the first encounter recorded for a patient, looks back between 7 and 365 days in the past and sees whether or not there are measured creatinine values. If there are, the mean of those values are put into the dummy row. Otherwise, a value calculated based on the estimated glomerular filtration rate (eGFR) equation from A New Equation to Estimate Glomerular Filtration Rate (Levey et. Al, 2009, https://pubmed.ncbi.nlm.nih.gov/19414839/) is used instead in the dummy row.  \n",
    "\n",
    "### parallelizeAnalysis()\n",
    "\n",
    "Parallelizes the analysis.\n",
    "\n",
    "### returnAKIpatients()\n",
    "\n",
    "Finds the patients with AKI according to the Rolling Window and/or the back-calculated definitions... runtime significantly depends on which definition you care for.\n",
    "\n",
    "### addDeltaCols()\n",
    "\n",
    "The way in which AKI is measured is based on the change in creatinine over a given period of time. As a proxy, $\\Delta creat$ and $\\Delta time$ columns are created to measure the change from one time point to another. This function calculates those values via the Split-Apply-Combine methodology on the original data frame: splitting by encounter, transforming via a backward shift, then taking the difference of values, then a forward shift, and then recombining the dataframe object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "code_folding": [
     36,
     71
    ]
   },
   "outputs": [],
   "source": [
    "def returnAKIpatients(df, aki_calc_type = 'both', keep_extra_cols = True, num_cores=4):\n",
    "    \n",
    "    if aki_calc_type == 'rolling_window':\n",
    "        #Add the delta columns as described above\n",
    "        d = add_delta_cols(df)\n",
    "        \n",
    "        #Two conditions for rolling-window definition\n",
    "        condition1 = np.logical_and(d.delta_creat >= 0.3, d.delta_time <= datetime.timedelta(hours=48))\n",
    "        condition2 = np.logical_and(d.delta_creat >= d.creat.shift(1)*0.5, d.delta_time <= datetime.timedelta(days=7))    \n",
    "    \n",
    "        d['aki'] = condition1 | condition2\n",
    "        \n",
    "    elif aki_calc_type == 'back_calc':\n",
    "        #Now, we gotta go through the process of creating the dummy rows\n",
    "        split_dfs = np.array_split(df, num_cores)\n",
    "        with Pool(num_cores) as p:\n",
    "            result = p.map(add_rows, split_dfs)\n",
    "            d_ = pd.concat(result)\n",
    "        d = add_delta_cols(d_)\n",
    "        condition2 = np.logical_and(d.delta_creat >= d.creat.shift(1)*0.5, d.delta_time < datetime.timedelta(days=7))    \n",
    "        d['aki'] = condition2 & (d.delta_time == datetime.timedelta(0)) #Remember, back-calc doesn't include the 0.3 increase criterion... has to be a 50% increase\n",
    "        \n",
    "    elif aki_calc_type == 'both':\n",
    "        split_dfs = np.array_split(df, num_cores)\n",
    "        with Pool(num_cores) as p:\n",
    "            result = p.map(add_rows, split_dfs)\n",
    "            d_ = pd.concat(result)\n",
    "        d = add_delta_cols(d_)\n",
    "        \n",
    "        condition1 = np.logical_and(d.delta_creat >= 0.3, d.delta_time < datetime.timedelta(hours=48))\n",
    "        condition2 = np.logical_and(d.delta_creat >= d.creat.shift(1)*0.5, d.delta_time < datetime.timedelta(days=7))    \n",
    "        \n",
    "        d['aki'] = condition1 | condition2\n",
    "    \n",
    "    return d\n",
    "\n",
    "def add_rows(df):\n",
    "    '''\n",
    "    Input: Pandas data frame\n",
    "    Output: Pandas data frame\n",
    "    \n",
    "    This function is the bulk of the computation - it adds dummy rows with the appropriate back-calculated values\n",
    "    at the first encounter row. If one is only interested in those patients which have AKI according to the \n",
    "    Rolling Window definition, the code should run in less than a minute and *add_rows()* isn't necessary. \n",
    "    If you are interested in back-calculated AKI cases, then the analysis takes a bit longer \n",
    "    (although still under an hour) and that's where *add_rows()* comes in. It simply finds the first encounter \n",
    "    recorded for a patient, looks back between 7 and 365 days in the past and sees whether or not there are measured\n",
    "    creatinine values. If there are, the mean of those values are put into the dummy row. Otherwise, a value \n",
    "    calculated based on the estimated glomerular filtration rate (eGFR) equation from A New Equation to Estimate \n",
    "    Glomerular Filtration Rate (Levey et. Al, 2009, https://pubmed.ncbi.nlm.nih.gov/19414839/) is used instead \n",
    "    in the dummy row.  \n",
    "    '''\n",
    "    patient_dfs = df.groupby(['mrn'], sort=False) \n",
    "    patients = dict()\n",
    "    \n",
    "    for mrn, pat_df in patient_dfs:\n",
    "        patients[mrn] = pat_df\n",
    "        backcalc_rows = np.array(pat_df.reset_index().drop_duplicates(['mrn', 'enc']).index)\n",
    "        times_to_consider = [pat_df.iloc[indx].time for indx in backcalc_rows]\n",
    "\n",
    "        new_rows = pat_df.iloc[backcalc_rows].copy()\n",
    "        for i in range(1,len(times_to_consider)):\n",
    "            new_rows.iloc[i, new_rows.columns.get_loc('creat')] = pat_df.loc[np.logical_and(times_to_consider[i] - pat_df.time < datetime.timedelta(days=365),times_to_consider[i] - pat_df.time > datetime.timedelta(days=7)), 'creat'].mean()\n",
    "\n",
    "        mini_dfs = np.split(pat_df, backcalc_rows[1:])\n",
    "        mini_dfs = [pd.concat([new_rows.iloc[[indx]], dataframe]) for indx, dataframe in enumerate(mini_dfs)]\n",
    "        pat_df = pd.concat(mini_dfs)\n",
    "        patients[mrn] = pat_df\n",
    "        \n",
    "    return pd.concat(list(patients.values()))\n",
    "\n",
    "def add_delta_cols(df):\n",
    "    delta_df = df.groupby(['mrn', 'enc']).shift(-1) - df\n",
    "    df['delta_creat'] = np.round(delta_df['creat'].shift(1), decimals = 1)\n",
    "    df['delta_time'] = delta_df['time'].shift(1)\n",
    "    firstencs = df.reset_index().drop_duplicates('mrn') #Similarly, df.groupby(['mrn']).head(1)\n",
    "    df['first_enc'] = [i in firstencs.index for i in range(df.shape[0])]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the rolling-window code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_both = returnAKIpatients(df, aki_calc_type = 'both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_rw = returnAKIpatients(df, aki_calc_type = 'rolling_window')\n",
    "df_rw.reset_index(inplace=True)\n",
    "patient=100 # Should work for any value of patient\n",
    "#df_rw.iloc[np.array([[i-2, i-1, i, i+1, i+2] for i in np.where(df_rw['aki'])[0]]).flatten()][5*patient:5*patient+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1441707, 6) (1441707, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pat_mrn_id</th>\n",
       "      <th>pat_enc_csn_id</th>\n",
       "      <th>time</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>aki</th>\n",
       "      <th>aki_stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MR1000041</td>\n",
       "      <td>115884935</td>\n",
       "      <td>2015-06-14T20:59:00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MR1000041</td>\n",
       "      <td>115884935</td>\n",
       "      <td>2015-06-15T07:54:00</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MR1000041</td>\n",
       "      <td>115884935</td>\n",
       "      <td>2015-06-16T07:02:00</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MR1000041</td>\n",
       "      <td>115884935</td>\n",
       "      <td>2015-06-17T07:11:00</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MR1000041</td>\n",
       "      <td>117378943</td>\n",
       "      <td>2015-07-18T08:39:00</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pat_mrn_id  pat_enc_csn_id                 time  creatinine    aki  \\\n",
       "0  MR1000041       115884935  2015-06-14T20:59:00         1.6  False   \n",
       "1  MR1000041       115884935  2015-06-15T07:54:00         0.9  False   \n",
       "2  MR1000041       115884935  2015-06-16T07:02:00         0.9  False   \n",
       "3  MR1000041       115884935  2015-06-17T07:11:00         0.9  False   \n",
       "4  MR1000041       117378943  2015-07-18T08:39:00         1.1  False   \n",
       "\n",
       "   aki_stage  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yu = pd.read_csv(r'H:\\Data\\Standardized AKI definition\\dataset\\aki flagger inpatient 2014-2018.csv')\n",
    "df_yu['aki'] = df_yu['aki'].astype('bool')\n",
    "print(df_yu.shape, df_rw.shape)\n",
    "df_yu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173632, 74190)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yu.aki.sum(), df_rw.aki.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.all(df_rw.reset_index().enc == df_yu.pat_enc_csn_id)) #Check whether the encounters are the same\n",
    "np.all(df_yu.aki.astype('bool') == df_rw.reset_index().aki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/saranmedical-smile/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/saranmedical-smile/opt/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2bfb436c948b>\u001b[0m in \u001b[0;36mreturnAKIpatients\u001b[0;34m(df, aki_calc_type, keep_extra_cols, num_cores)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msplit_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_dfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0md_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_delta_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_bc = returnAKIpatients(df, aki_calc_type = 'back_calc')\n",
    "patient = 0\n",
    "#df_bc.iloc[np.array([[i-2, i-1, i, i+1, i+2] for i in np.where(df_bc['aki'])[0]]).flatten()][5*patient:5*patient+5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### might get rid of this in a minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     35,
     49,
     69
    ]
   },
   "outputs": [],
   "source": [
    "def add_rows(df):\n",
    "    '''\n",
    "    Input: Pandas data frame\n",
    "    Output: Pandas data frame\n",
    "    \n",
    "    This function is the bulk of the computation - it adds dummy rows with the appropriate back-calculated values\n",
    "    at the first encounter row. If one is only interested in those patients which have AKI according to the \n",
    "    Rolling Window definition, the code should run in less than a minute and *add_rows()* isn't necessary. \n",
    "    If you are interested in back-calculated AKI cases, then the analysis takes a bit longer \n",
    "    (although still under an hour) and that's where *add_rows()* comes in. It simply finds the first encounter \n",
    "    recorded for a patient, looks back between 7 and 365 days in the past and sees whether or not there are measured\n",
    "    creatinine values. If there are, the mean of those values are put into the dummy row. Otherwise, a value \n",
    "    calculated based on the estimated glomerular filtration rate (eGFR) equation from A New Equation to Estimate \n",
    "    Glomerular Filtration Rate (Levey et. Al, 2009, https://pubmed.ncbi.nlm.nih.gov/19414839/) is used instead \n",
    "    in the dummy row.  \n",
    "    '''\n",
    "    patient_dfs = df.groupby(['mrn'], sort=False) \n",
    "    patients = dict()\n",
    "    \n",
    "    for mrn, pat_df in patient_dfs:\n",
    "        patients[mrn] = pat_df\n",
    "        backcalc_rows = np.array(pat_df.reset_index().drop_duplicates(['mrn', 'enc']).index)\n",
    "        times_to_consider = [pat_df.iloc[indx].time for indx in backcalc_rows]\n",
    "\n",
    "        new_rows = pat_df.iloc[backcalc_rows].copy()\n",
    "        for i in range(1,len(times_to_consider)):\n",
    "            new_rows.iloc[i, new_rows.columns.get_loc('creat')] = pat_df.loc[np.logical_and(times_to_consider[i] - pat_df.time < datetime.timedelta(days=365),times_to_consider[i] - pat_df.time > datetime.timedelta(days=7)), 'creat'].mean()\n",
    "\n",
    "        mini_dfs = np.split(pat_df, backcalc_rows[1:])\n",
    "        mini_dfs = [pd.concat([new_rows.iloc[[indx]], dataframe]) for indx, dataframe in enumerate(mini_dfs)]\n",
    "        pat_df = pd.concat(mini_dfs)\n",
    "        patients[mrn] = pat_df\n",
    "        \n",
    "    return pd.concat(list(patients.values()))\n",
    "\n",
    "def parallelize_analysis(df, func=add_rows, num_cores = 4):\n",
    "    '''\n",
    "    Input: dataframe, generic function, number of cpu processors to dedicate to parallelization\n",
    "    Output: function applied to dataframe\n",
    "    \n",
    "    Generic parallelizing function, simple splits the dataframe, performs the operations on the split dataframes,\n",
    "    \n",
    "    '''\n",
    "    split_dfs = np.array_split(df, num_cores)\n",
    "    with Pool(num_cores) as p:\n",
    "        result = p.map(func, split_dfs)\n",
    "        df = pd.concat(result)\n",
    "    return df\n",
    "\n",
    "def returnAKIpatients(df, aki_calc_type = 'both'):\n",
    "    #Redefine delta creat and delta time cols\n",
    "    delta_df = d.groupby(['mrn', 'enc']).shift(-1) - df\n",
    "    df['delta_creat'] = delta_df['creat'].shift(1)\n",
    "    df['delta_time'] = delta_df['time'].shift(1)\n",
    "    \n",
    "    #Rolling Window conditions\n",
    "    if aki_calc_type == 'both':\n",
    "        condition1 = np.logical_and(df.delta_creat > 0.3, df.delta_time < datetime.timedelta(hours=48))\n",
    "        condition2 = np.logical_and(df.delta_creat > df.creat.shift(1)*0.5, df.delta_time < datetime.timedelta(days=7))\n",
    "        df['aki'] = condition1 | condition2\n",
    "    elif aki_calc_type == 'rolling_window':\n",
    "        condition1 = np.logical_and(df.delta_creat > 0.3, df.delta_time < datetime.timedelta(hours=48))\n",
    "        condition2 = np.logical_and(df.delta_creat > df.creat.shift(1)*0.5, df.delta_time < datetime.timedelta(days=7))\n",
    "        df['aki'] = (condition1 | condition2) & (df.delta_time != datetime.timedelta(0))\n",
    "    elif aki_calc_type == 'back_calc':\n",
    "        condition = np.logical_and(df.delta_creat > df.creat.shift(1)*0.5, df.delta_time < datetime.timedelta(days=7))\n",
    "        df['aki'] = condition & (df.delta_time == datetime.timedelta(0))\n",
    "    return df\n",
    "\n",
    "def add_delta_cols(df):\n",
    "    delta_df = df.groupby(['mrn', 'enc']).shift(-1) - df\n",
    "    df['delta_creat'] = delta_df['creat'].shift(1)\n",
    "    df['delta_time'] = delta_df['time'].shift(1)\n",
    "    firstencs = df.reset_index().drop_duplicates('mrn') #Similarly, df.groupby(['mrn']).head(1)\n",
    "    df['first_enc'] = [i in firstencs.index for i in range(df.shape[0])]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
