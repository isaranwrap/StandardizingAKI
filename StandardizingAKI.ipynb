{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime, random\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in file; managing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pat_mrn_id                 int64\n",
      "pat_enc_csn_id             int64\n",
      "time              datetime64[ns]\n",
      "creatinine               float64\n",
      "dtype: object\n",
      "CPU times: user 1.95 s, sys: 255 ms, total: 2.2 s\n",
      "Wall time: 2.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Read in dataframe\n",
    "df = pd.read_csv('~/Desktop/patr/StandardizingAKI/inpatient 2014-2018 creatinine.csv') #1441707, 4\n",
    "df.pat_mrn_id = df.pat_mrn_id.str.strip('MR').astype('int') #Index with integers --> it's much quicker\n",
    "df.time = pd.to_datetime(df.time) # Convert to pandas datetime format\n",
    "print(df.dtypes) # Confirm all the column types are as we want it\n",
    "\n",
    "df.columns = ['mrn', #Renaming columns for ease\n",
    "              'enc',\n",
    "              'time',\n",
    "              'creat'] \n",
    "df.set_index(['mrn', 'enc'], inplace=True) #Turn the index into a hierarchical tuple (mrn, enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions: add_rows(df),  add_delta_cols(df), returnAKIpatients(df), parallelizeAnalysis(df, num_cores)\n",
    "\n",
    "### add_rows()\n",
    "\n",
    "    Input: Pandas data frame \n",
    "\n",
    "    Output: Pandas data frame (w/ extra dummy rows containing back-calculated values)\n",
    "\n",
    "This function is the bulk of the computation - it adds dummy rows with the appropriate back-calculated values at the first encounter row. If one is only interested in those patients which have AKI according to the Rolling Window definition, the code should run in less than a minute and *add_rows()* isn't necessary. If you are interested in back-calculated AKI cases, then the analysis takes a bit longer (although still under an hour) and that's where *add_rows()* comes in. It simply finds the first encounter recorded for a patient, looks back between 7 and 365 days in the past and sees whether or not there are measured creatinine values. If there are, the mean of those values are put into the dummy row. Otherwise, a value calculated based on the estimated glomerular filtration rate (eGFR) equation from A New Equation to Estimate Glomerular Filtration Rate (Levey et. Al, 2009, https://pubmed.ncbi.nlm.nih.gov/19414839/) is used instead in the dummy row.  \n",
    "\n",
    "### parallelizeAnalysis()\n",
    "\n",
    "Parallelizes the analysis.\n",
    "\n",
    "### returnAKIpatients()\n",
    "\n",
    "Finds the patients with AKI according to the Rolling Window and/or the back-calculated definitions... runtime significantly depends on which definition you care for.\n",
    "\n",
    "### addDeltaCols()\n",
    "\n",
    "The way in which AKI is measured is based on the change in creatinine over a given period of time. As a proxy, $\\Delta creat$ and $\\Delta time$ columns are created to measure the change from one time point to another. This function calculates those values via the Split-Apply-Combine methodology on the original data frame: splitting by encounter, transforming via a backward shift, then taking the difference of values, then a forward shift, and then recombining the dataframe object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     37,
     51,
     71
    ]
   },
   "outputs": [],
   "source": [
    "def add_rows(df):\n",
    "    '''\n",
    "    Input: Pandas data frame\n",
    "    Output: Pandas data frame\n",
    "    \n",
    "    This function is the bulk of the computation - it adds dummy rows with the appropriate back-calculated values\n",
    "    at the first encounter row. If one is only interested in those patients which have AKI according to the \n",
    "    Rolling Window definition, the code should run in less than a minute and *add_rows()* isn't necessary. \n",
    "    If you are interested in back-calculated AKI cases, then the analysis takes a bit longer \n",
    "    (although still under an hour) and that's where *add_rows()* comes in. It simply finds the first encounter \n",
    "    recorded for a patient, looks back between 7 and 365 days in the past and sees whether or not there are measured\n",
    "    creatinine values. If there are, the mean of those values are put into the dummy row. Otherwise, a value \n",
    "    calculated based on the estimated glomerular filtration rate (eGFR) equation from A New Equation to Estimate \n",
    "    Glomerular Filtration Rate (Levey et. Al, 2009, https://pubmed.ncbi.nlm.nih.gov/19414839/) is used instead \n",
    "    in the dummy row.  \n",
    "    '''\n",
    "    patient_dfs = df.groupby(['mrn'], sort=False) \n",
    "    patients = dict()\n",
    "    \n",
    "    for mrn, pat_df in patient_dfs:\n",
    "        patients[mrn] = pat_df\n",
    "        backcalc_rows = np.array(pat_df.reset_index().drop_duplicates(['mrn', 'enc']).index)\n",
    "        times_to_consider = [pat_df.iloc[indx].time for indx in backcalc_rows]\n",
    "\n",
    "        new_rows = pat_df.iloc[backcalc_rows].copy()\n",
    "        for i in range(1,len(times_to_consider)):\n",
    "            new_rows.iloc[i, new_rows.columns.get_loc('creat')] = pat_df.loc[np.logical_and(times_to_consider[i] - pat_df.time < datetime.timedelta(days=365),times_to_consider[i] - pat_df.time > datetime.timedelta(days=7)), 'creat'].mean()\n",
    "\n",
    "        mini_dfs = np.split(pat_df, backcalc_rows[1:])\n",
    "        mini_dfs = [pd.concat([new_rows.iloc[[indx]], dataframe]) for indx, dataframe in enumerate(mini_dfs)]\n",
    "        pat_df = pd.concat(mini_dfs)\n",
    "        patients[mrn] = pat_df\n",
    "        \n",
    "    return pd.concat(list(patients.values()))\n",
    "\n",
    "\n",
    "\n",
    "def parallelize_analysis(df, func=add_rows, num_cores = 4):\n",
    "    '''\n",
    "    Input: dataframe, generic function, number of cpu processors to dedicate to parallelization\n",
    "    Output: function applied to dataframe\n",
    "    \n",
    "    Generic parallelizing function, simple splits the dataframe, performs the operations on the split dataframes,\n",
    "    \n",
    "    '''\n",
    "    split_dfs = np.array_split(df, num_cores)\n",
    "    with Pool(num_cores) as p:\n",
    "        result = p.map(func, split_dfs)\n",
    "        df = pd.concat(result)\n",
    "    return df\n",
    "\n",
    "def returnAKIpatients(df, aki_calc_type = 'both'):\n",
    "    #Redefine delta creat and delta time cols\n",
    "    delta_df = d.groupby(['mrn', 'enc']).shift(-1) - df\n",
    "    df['delta_creat'] = delta_df['creat'].shift(1)\n",
    "    df['delta_time'] = delta_df['time'].shift(1)\n",
    "    \n",
    "    #Rolling Window conditions\n",
    "    if aki_calc_type == 'both':\n",
    "        condition1 = np.logical_and(df.delta_creat > 0.3, df.delta_time < datetime.timedelta(hours=48))\n",
    "        condition2 = np.logical_and(df.delta_creat > df.creat.shift(1)*0.5, df.delta_time < datetime.timedelta(days=7))\n",
    "        df['aki'] = condition1 | condition2\n",
    "    elif aki_calc_type == 'rolling_window':\n",
    "        condition1 = np.logical_and(df.delta_creat > 0.3, df.delta_time < datetime.timedelta(hours=48))\n",
    "        condition2 = np.logical_and(df.delta_creat > df.creat.shift(1)*0.5, df.delta_time < datetime.timedelta(days=7))\n",
    "        df['aki'] = (condition1 | condition2) & (df.delta_time != datetime.timedelta(0))\n",
    "    elif aki_calc_type == 'back_calc':\n",
    "        condition = np.logical_and(df.delta_creat > df.creat.shift(1)*0.5, df.delta_time < datetime.timedelta(days=7))\n",
    "        df['aki'] = condition & (df.delta_time == datetime.timedelta(0))\n",
    "    return df\n",
    "\n",
    "def add_delta_cols(df):\n",
    "    delta_df = df.groupby(['mrn', 'enc']).shift(-1) - df\n",
    "    df['delta_creat'] = delta_df['creat'].shift(1)\n",
    "    df['delta_time'] = delta_df['time'].shift(1)\n",
    "    #df[['delta_time, delta_creat']] = delta_df[['time', 'creatinine']]\n",
    "    firstencs = df.reset_index().drop_duplicates('mrn') #Similarly, df.groupby(['mrn']).head(1)\n",
    "    df['first_enc'] = [i in firstencs.index for i in range(df.shape[0])]\n",
    "    df.reset_index(inplace=True)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
